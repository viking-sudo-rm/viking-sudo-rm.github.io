@misc{ramesh2021zeroshot,
  title={Zero-shot text-to-image generation}, 
  author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
  year={2021},
  eprint={2102.12092},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/pdf/2102.12092.pdf},
}

@misc{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with CLIP latents}, 
  author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
  year={2022},
  eprint={2204.06125},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/pdf/2204.06125.pdf}
}

@misc{rombach2021highresolution,
  title={High-resolution image synthesis with latent diffusion models}, 
  author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
  year={2021},
  eprint={2112.10752},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/pdf/2112.10752.pdf}
}

@article{silver2016go,
  author={Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  title={Mastering the game of Go with deep neural networks and tree search},
  journal={Nature},
  year={2016},
  volume={529},
  number={7587},
  pages={484-489},
  url={https://doi.org/10.1038/nature16961},
}

@article{silver2017gozero,
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  title={Mastering the game of Go without human knowledge},
  journal={Nature},
  year={2017},
  volume={550},
  number={7676},
  pages={354-359},
  url={https://doi.org/10.1038/nature24270}
}

@misc{ouyang2022training,
  title={Training language models to follow instructions with human feedback}, 
  author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
  year={2022},
  eprint={2203.02155},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/2203.02155.pdf}
}

@misc{openai2023gpt4,
  title={GPT-4 technical report}, 
  author={OpenAI},
  year={2023},
  eprint={2303.08774},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/2303.08774.pdf}
}

@online{openai2022chatgpt,
  author = "OpenAI",
  title = "Introducing ChatGPT",
  year = 2022,
  url = "https://openai.com/blog/chatgpt"
}

@article{forcada2002flann,
  title={Neural networks: automata and formal models of computation},
  author={Mikel L. Forcada},
  publisher={Universitat d'Alacant},
  year={2002},
  url={https://www.dlsi.ua.es/~mlf/nnafmc/pbook.pdf}
}

@article{mcculloch1943nn,
  author={McCulloch, Warren S. and Pitts, Walter},
  title={A logical calculus of the ideas immanent in nervous activity},
  journal={The bulletin of mathematical biophysics},
  year={1943},
  volume={5},
  number={4},
  pages={115-133},
}

@incollection{kleene1956automata,
  title = {Representation of events in nerve nets and finite automata},
  booktitle = {Automata Studies. (AM-34), Volume 34},
  author = {S. C. Kleene},
  editor = {C. E. Shannon and J. McCarthy},
  publisher = {Princeton University Press},
  address = {Princeton},
  pages = {3--42},
  year = {1956},
}

@book{minsky1967computation,
  title={Computation: finite and infinite machines},
  author={Minsky, Marvin},
  year={1967},
  publisher={Prentice-Hall, Inc.},
  address={Englewood Cliffs, NJ},
}

@online{logicalneuron,
  title = {A logical neuron},
  url = {https://marlin.life.utsa.edu/mcculloch-and-pitts.html},
  author = {C.J. Wilson Laboratory at UTSA},
  howpublished = {Website},
  note = {Accessed on 2023-09-06}
}

@article{elman1990rnn,
  title = {Finding structure in time},
  journal = {Cognitive Science},
  volume = {14},
  number = {2},
  pages = {179-211},
  year = {1990},
  issn = {0364-0213},
  author = {Jeffrey L. Elman},
  url = {https://doi.org/10.1016/0364-0213(90)90002-E},
}

@inproceedings{steijvers1996csrnn,
  author       = {Mark Steijvers and Peter Grünwald},
  title        = {A recurrent network that performs a context-sensitive prediction task},
  booktitle    = {Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society},
  year         = {1996},
  edition      = {1st},
  pages        = {5},
  publisher    = {Routledge},
}

@article{gers2001lstm,
  author={Gers, F.A. and Schmidhuber, E.},
  journal={IEEE Transactions on Neural Networks}, 
  title={LSTM recurrent networks learn simple context-free and context-sensitive languages}, 
  year={2001},
  volume={12},
  number={6},
  pages={1333-1340},
  url={https://doi.org/10.1109/72.963769}
}

@inproceedings{das1992stack,
  title={Learning context-free grammars: capabilities and limitations of a recurrent neural network with an external stack memory},
  author={Das, Sreerupa and Giles, C Lee and Sun, Guo-Zheng},
  booktitle={Proceedings of The Fourteenth Annual Conference of Cognitive Science Society},
  year={1992},
  pages={14},
  address={Indiana University}
}

@article{siegelmann1996farnn,
  author = {Siegelmann, Hava T.},
  title = {Recurrent neural networks and finite automata},
  journal = {Computational Intelligence},
  volume = {12},
  number = {4},
  pages = {567-574},
  url = {https://doi.org/10.1111/j.1467-8640.1996.tb00277.x},
  year = {1996}
}

@inproceedings{siegelmann1992turing,
  author = {Siegelmann, Hava T. and Sontag, Eduardo D.},
  title = {On the computational power of neural nets},
  year = {1992},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/130385.130432},
  booktitle = {Proceedings of the Fifth Annual Workshop on Computational Learning Theory},
  pages = {440--449},
  numpages = {10},
  location = {Pittsburgh, Pennsylvania, USA},
  series = {COLT '92}
}

@inproceedings{chen2018recurrent,
  title = {Recurrent neural networks as weighted language recognizers},
  author = {Chen, Yining and Gilroy, Sorcha and Maletti, Andreas and May, Jonathan and Knight, Kevin},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  year = {2018},
  address = {New Orleans, Louisiana},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/N18-1205.pdf},
  pages = {2261--2271},
}

@inproceedings{weiss2018practical,
  title = {On the practical computational power of finite precision RNNs for language recognition},
  author = {Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  year = {2018},
  address = {Melbourne, Australia},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/P18-2117.pdf},
  pages = {740--745},
}

@inproceedings{merrill2019sequential,
  title = {Sequential neural networks as automata},
  author = {Merrill, William},
  booktitle = {Proceedings of the Workshop on Deep Learning and Formal Languages: Building Bridges},
  year = {2019},
  address = {Florence},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/W19-3901.pdf},
  pages = {1--13},
}

@inproceedings{tran2018hierarchy,
  title = {The importance of being recurrent for modeling hierarchical structure},
  author = {Tran, Ke and Bisazza, Arianna and Monz, Christof},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  year = {2018},
  address = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/D18-1503.pdf},
  pages = {4731--4736},
  abstract = {Recent work has shown that recurrent neural networks (RNNs) can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks (Blevins et al., 2018) such as language modeling (Linzen et al., 2016; Gulordava et al., 2018) and neural machine translation (Shi et al., 2016). In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks (Gehring et al., 2017; Vaswani et al., 2017). In this work, we compare the two architectures{---}recurrent versus non-recurrent{---}with respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose. The code and data used in our experiments is available at \url{https://github.com/ ketranm/fan_vs_rnn}},
}

@misc{korsky2019computational,
  title={On the computational power of RNNs}, 
  author={Samuel A. Korsky and Robert C. Berwick},
  year={2019},
  eprint={1906.06349},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/1906.06349.pdf}
}

@inproceedings{suzgun2019lstm,
    title = {LSTM networks can perform dynamic counting},
    author = {Suzgun, Mirac and Belinkov, Yonatan and Shieber, Stuart and Gehrmann, Sebastian},
    booktitle = {Proceedings of the Workshop on Deep Learning and Formal Languages: Building Bridges},
    year = {2019},
    address = {Florence},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/W19-3905.pdf},
    pages = {44--54},}

@inproceedings{ebrahimi2020dyck,
  title = {How can self-attention networks recognize Dyck-n languages?},
  author = {Ebrahimi, Javid and Gelda, Dhruv and Zhang, Wei},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  year = {2020},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2020.findings-emnlp.384.pdf},
  pages = {4301--4306},
}

@inproceedings{deletang2023chomsky,
  title={Neural networks and the Chomsky hierarchy},
  author={Gregoire Delétang and Anian Ruoss and Jordi Grau-Moya and Tim Genewein and Li Kevin Wenliang and Elliot Catt and Chris Cundy and Marcus Hutter and Shane Legg and Joel Veness and Pedro A Ortega},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=WbxHAzkeQcn}
}

@inproceedings{merrill2020formal,
  title = {A formal hierarchy of RNN architectures},
  author = {Merrill, William and Weiss, Gail and Goldberg, Yoav and Schwartz, Roy and Smith, Noah A. and Yahav, Eran},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  year = {2020},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2020.acl-main.43.pdf},
  pages = {443--459},
}

@book{zhang2023dive,
  title={Dive into deep learning},
  author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  publisher={Cambridge University Press},
  url={https://D2L.ai},
  year={2023}
}

@inproceedings{vaswani2017transformer,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher = {Curran Associates, Inc.},
  title = {Attention is all you need},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume = {30},
  year = {2017}
}

@inproceedings{perez2019turing,
  title={On the Turing completeness of modern neural network architectures},
  author={Jorge Pérez and Javier Marinković and Pablo Barceló},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=HyGBdo0qFm},
}

@article{perez2021turing,
  author  = {Jorge Pérez and Pablo Barceló and Javier Marinkovic},
  title   = {Attention is Turing-complete},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {75},
  pages   = {1--35},
  url     = {https://jmlr.org/papers/volume22/20-302/20-302.pdf}
}

@article{hahn2020limitations,
  title = {Theoretical limitations of self-attention in neural sequence models},
  author = {Hahn, Michael},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {8},
  year = {2020},
  address = {Cambridge, MA},
  publisher = {MIT Press},
  url = {https://aclanthology.org/2020.tacl-1.11.pdf},
  pages = {156--171},
}

@inproceedings{chiang2022overcoming,
  title = {Overcoming a theoretical limitation of self-attention},
  author = {Chiang, David and Cholak, Peter},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year = {2022},
  address = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2022.acl-long.527.pdf},
  pages = {7654--7664},
}

@inproceedings{yao2021bounded,
  title = {Self-attention networks can process bounded hierarchical languages},
  author = {Yao, Shunyu and Peng, Binghui and Papadimitriou, Christos and Narasimhan, Karthik},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  year = {2021},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2021.acl-long.292.pdf},
  pages = {3770--3785},
}

@inproceedings{bhattamishra2020ability,
  title = {On the ability and limitations of Transformers to recognize formal languages},
  author = {Bhattamishra, Satwik and Ahuja, Kabir and Goyal, Navin},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2020},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2020.emnlp-main.576.pdf},
  pages = {7096--7116},
}


@inproceedings{weiss2021rasp,
  title = {Thinking like Transformers},
  author = {Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages = {11080--11090},
  year = {2021},
  editor = {Meila, Marina and Zhang, Tong},
  volume = {139},
  series = {Proceedings of Machine Learning Research},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v139/weiss21a/weiss21a.pdf},
}

@article{hao2022circuit,
  title = {Formal language recognition by hard attention Transformers: perspectives from circuit complexity},
  author = {Hao, Yiding and Angluin, Dana and Frank, Robert},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {10},
  year = {2022},
  address = {Cambridge, MA},
  publisher = {MIT Press},
  url = {https://aclanthology.org/2022.tacl-1.46.pdf},
  pages = {800--810},
}

@article{merrill2022saturated,
  title = {Saturated Transformers are constant-depth threshold circuits},
  author = {Merrill, William and Sabharwal, Ashish and Smith, Noah A.},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {10},
  year = {2022},
  address = {Cambridge, MA},
  publisher = {MIT Press},
  url = {https://aclanthology.org/2022.tacl-1.49.pdf},
  pages = {843--856},
}

@article{merrill2023parallelism,
  title = {The parallelism tradeoff: limitations of log-precision Transformers},
  author = {Merrill, William and Sabharwal, Ashish},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {11},
  year = {2023},
  address = {Cambridge, MA},
  publisher = {MIT Press},
  url = {https://aclanthology.org/2023.tacl-1.31.pdf},
  pages = {531--545},
}

@inproceedings{chiang2023tighter,
  title = {Tighter bounds on the expressivity of Transformer encoders},
  author = {Chiang, David and Cholak, Peter and Pillay, Anand},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages = {5544--5562},
  year = {2023},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = {202},
  series = {Proceedings of Machine Learning Research},
  month = {23--29 Jul},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v202/chiang23a/chiang23a.pdf},
}

@misc{merrill2023logic,
  title={A logic for expressing log-precision Transformers}, 
  author={William Merrill and Ashish Sabharwal},
  year={2023},
  eprint={2210.02671},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2210.02671v4.pdf},
}

@inproceedings{dehghani2019ut,
  title={Universal Transformers},
  author={Mostafa Dehghani and Stephan Gouws and Oriol Vinyals and Jakob Uszkoreit and Lukasz Kaiser},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=HyzdRiR9Y7},
}

@inproceedings{devlin2019bert,
  title = {BERT: pre-training of deep bidirectional Transformers for language understanding},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  year = {2019},
  address = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/N19-1423.pdf},
  pages = {4171--4186},
}

@misc{brown2020gpt,
  title={Language models are few-shot learners}, 
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year={2020},
  eprint={2005.14165},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/2005.14165.pdf}
}

@inproceedings{grefenstette2015transduce,
  author = {Grefenstette, Edward and Hermann, Karl Moritz and Suleyman, Mustafa and Blunsom, Phil},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
  publisher = {Curran Associates, Inc.},
  title = {Learning to transduce with unbounded memory},
  url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/b9d487a30398d42ecff55c228ed5652b-Paper.pdf},
  volume = {28},
  year = {2015}
}

@inproceedings{hao2018context,
  title = {Context-free transductions with neural stacks},
  author = {Hao, Yiding and Merrill, William and Angluin, Dana and Frank, Robert and Amsel, Noah and Benz, Andrew and Mendelsohn, Simon},
  booktitle = {Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  year = {2018},
  address = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/W18-5433.pdf},
  pages = {306--315},
}

@misc{joulin2015inferring,
  title={Inferring algorithmic patterns with stack-augmented recurrent nets}, 
  author={Armand Joulin and Tomas Mikolov},
  year={2015},
  eprint={1503.01007},
  archivePrefix={arXiv},
  primaryClass={cs.NE},
  url={https://arxiv.org/pdf/1503.01007.pdf}
}

@misc{suzgun2019memory,
  title={Memory-augmented recurrent neural networks can learn generalized Dyck languages}, 
  author={Mirac Suzgun and Sebastian Gehrmann and Yonatan Belinkov and Stuart M. Shieber},
  year={2019},
  eprint={1911.03329},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/1911.03329.pdf}
}

@inproceedings{dusell2023nstack,
  title={The surprising computational power of nondeterministic stack RNNs},
  author={Brian DuSell and David Chiang},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=o58JtGDs6y}
}

@inproceedings{rae2016scaling,
  author = {Rae, Jack and Hunt, Jonathan J and Danihelka, Ivo and Harley, Timothy and Senior, Andrew W and Wayne, Gregory and Graves, Alex and Lillicrap, Timothy},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
  publisher = {Curran Associates, Inc.},
  title = {Scaling memory-augmented neural networks with sparse reads and writes},
  url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/3fab5890d8113d0b5a4178201dc842ad-Paper.pdf},
  volume = {29},
  year = {2016}
}

@misc{graves2014ntm,
  title={Neural Turing machines}, 
  author={Alex Graves and Greg Wayne and Ivo Danihelka},
  year={2014},
  eprint={1410.5401},
  archivePrefix={arXiv},
  primaryClass={cs.NE},
  url={https://arxiv.org/pdf/1410.5401.pdf}
}

@misc{graves2017act,
  title={Adaptive computation time for recurrent neural networks}, 
  author={Alex Graves},
  year={2017},
  eprint={1603.08983},
  archivePrefix={arXiv},
  primaryClass={cs.NE},
  url={https://arxiv.org/pdf/1603.08983.pdf}
}

@misc{banino2021pondernet,
  title={PonderNet: learning to ponder}, 
  author={Andrea Banino and Jan Balaguer and Charles Blundell},
  year={2021},
  eprint={2107.05407},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2107.05407.pdf}
}

@inproceedings{amos2017optnet,
  title = {OptNet: differentiable optimization as a layer in neural networks},
  author = {Brandon Amos and J. Zico Kolter},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages = {136--145},
  year = {2017},
  editor = {Precup, Doina and Teh, Yee Whye},
  volume = {70},
  series = {Proceedings of Machine Learning Research},
  month = {06--11 Aug},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v70/amos17a/amos17a.pdf},
}

@inproceedings{wang2019satnet,
  title = {SATNet: bridging deep learning and logical reasoning using a differentiable satisfiability solver},
  author = {Wang, Po-Wei and Donti, Priya and Wilder, Bryan and Kolter, Zico},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages = {6545--6554},
  year = {2019},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = {97},
  series = {Proceedings of Machine Learning Research},
  month = {09--15 Jun},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v97/wang19e/wang19e.pdf},
}

@inproceedings{paulus2021comboptnet,
  title = {CombOptNet: fit the right NP-Hard problem by learning integer programming constraints},
  author = {Paulus, Anselm and Rolinek, Michal and Musil, Vit and Amos, Brandon and Martius, Georg},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages = {8443--8453},
  year = {2021},
  editor = {Meila, Marina and Zhang, Tong},
  volume = {139},
  series = {Proceedings of Machine Learning Research},
  month = {18--24 Jul},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v139/paulus21a/paulus21a.pdf},
}


@InProceedings{du2022irem,
  title = {Learning iterative reasoning through energy minimization},
  author = {Du, Yilun and Li, Shuang and Tenenbaum, Joshua and Mordatch, Igor},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning},
  pages = {5570--5582},
  year = {2022},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = {162},
  series = {Proceedings of Machine Learning Research},
  month = {17--23 Jul},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v162/du22d/du22d.pdf},
}

@inproceedings{bai2019deq,
  author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alché-Buc and E. Fox and R. Garnett},
  publisher = {Curran Associates, Inc.},
  title = {Deep equilibrium models},
  url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/01386bd6d8e091c2ab4c7c7de644d37b-Paper.pdf},
  volume = {32},
  year = {2019}
}

@inproceedings{liang2021deqood,
  title={Out-of-distribution generalization with deep equilibrium models},
  author={Liang, Kaiqu and Anil, Cem and Wu, Yuhuai and Grosse, Roger},
  booktitle={Uncertainty and Robustness in Deep Learning, ICML},
  year={2021}
}

@inproceedings{kojima2022zeroshot,
  author = {Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages = {22199--22213},
  publisher = {Curran Associates, Inc.},
  title = {Large language models are zero-shot reasoners},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf},
  volume = {35},
  year = {2022}
}

@inproceedings{wei2022cot,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and ichter, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages = {24824--24837},
  publisher = {Curran Associates, Inc.},
  title = {Chain-of-thought prompting elicits reasoning in large language models},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf},
  volume = {35},
  year = {2022}
}

@inproceedings{chung2021rnnbounded,
  author = {Chung, Stephen and Siegelmann, Hava},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages = {28431--28441},
  publisher = {Curran Associates, Inc.},
  title = {Turing completeness of bounded-precision recurrent neural networks},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/ef452c63f81d0105dd4486f775adec81-Paper.pdf},
  volume = {34},
  year = {2021}
}

@misc{gu2020hippo,
  title={HiPPO: recurrent memory with optimal polynomial projections}, 
  author={Albert Gu and Tri Dao and Stefano Ermon and Atri Rudra and Christopher Ré},
  year={2020},
  eprint={2008.07669},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2008.07669.pdf},
}

@misc{gu2021lssl,
  title={Combining recurrent, convolutional, and continuous-time models with linear state-space layers}, 
  author={Albert Gu and Isys Johnson and Karan Goel and Khaled Saab and Tri Dao and Atri Rudra and Christopher Ré},
  year={2021},
  eprint={2110.13985},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2110.13985.pdf}
}

@misc{gu2022efficiently,
  title={Efficiently modeling long sequences with structured state spaces}, 
  author={Albert Gu and Karan Goel and Christopher Ré},
  year={2022},
  eprint={2111.00396},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2111.00396.pdf}
}

@inproceedings{smith2023simplified,
  title={Simplified state space layers for sequence modeling},
  author={Jimmy T.H. Smith and Andrew Warrington and Scott Linderman},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=Ai8Hw3AXqks}
}

@misc{orvieto2023resurrecting,
  title={Resurrecting recurrent neural networks for long sequences}, 
  author={Antonio Orvieto and Samuel L Smith and Albert Gu and Anushan Fernando and Caglar Gulcehre and Razvan Pascanu and Soham De},
  year={2023},
  eprint={2303.06349},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2303.06349.pdf}
}

@misc{poli2023hyena,
  title={Hyena Hierarchy: towards larger convolutional language models}, 
  author={Michael Poli and Stefano Massaroli and Eric Nguyen and Daniel Y. Fu and Tri Dao and Stephen Baccus and Yoshua Bengio and Stefano Ermon and Christopher Ré},
  year={2023},
  eprint={2302.10866},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/pdf/2302.10866.pdf}
}

@misc{sun2023retnet,
  title={Retentive Network: a successor to Transformer for large language models}, 
  author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
  year={2023},
  eprint={2307.08621},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/2307.08621.pdf}
}

@misc{mahowald2023dissociating,
  title={Dissociating language and thought in large language models: a cognitive perspective}, 
  author={Kyle Mahowald and Anna A. Ivanova and Idan A. Blank and Nancy Kanwisher and Joshua B. Tenenbaum and Evelina Fedorenko},
  year={2023},
  eprint={2301.06627},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/pdf/2301.06627.pdf}
}
